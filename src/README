user: lmartel
user: andymo

We solved assignment 3 by using our existing assignment 2 code. 

Part 1
======

Our assignment 2 code already used exceptions in most situations to record errors. We were
catching them at the Rep layer and printing error messages. We moved the logging to where
the exceptions were thrown and stopped catching the exceptions.

We have defined a few general exception types that encapsulate the kinds of errors that can
occur in the system. They are found in Error.h. We attempt to use range_error for 
exceptions that correspond to invalid values, and runtime_error for other classes of exception.

In general we do not need to clean up after exceptions to ensure consistent state because most 
exceptions are thrown in convenient places, but for invalid deletions we do. The cleanup is
handled in instance.cpp in the deleteSelf methods for locations and segments. 

Part 2
======

We wrote an activity manager. It is based mostly on the implementation that was shown in 
the example. We made a few changes to the flow and to the information it tracks. When 
an activity is created, it is created in the "waiting" state. Also, we do not track
names of activities. We do not need them in our code because wherever we need to 
change an activity we have a reference to it.

We only use "ready", "waiting" and "executing" states for activities.

   Waiting: the activity cannot execute yet because it is blocked on something external. 
            for example, the forwarding activity "waits" when all segments are full.
   Ready: can be executed if now() > nextTime()
   Executing: The activity's reactor is responsible for executing its code at this point.
              When the code is done it must transition to waiting or ready.

We track the "ready" activities in a priority queue in our activity manager. When an activity
becomes ready we store it in the queue with its priority set to its nextTime().

Furthermore, we made the ActivityManager a subordinate of the engine. We added an
ActivityManagerRep to the rep layer and time is controlled with this. It is kind of strange
but we do not think it is any stranger than having an instance for Conn.

Part 3
======

We implemented a shipment class and several reactors. The shipment is responsible for knowing
its route and various statistics about itself.

The activity reactors are:

InjectionActivityReactor -- responsible for adding shipments to customer nodes.
ForwardingActivityReactor -- responsible for switching shipments onto segments from locations
TransferActivityReactor -- responsible for transferring a single shipment along a segment.

These activity reactors and their associated activities are created and controlled by reactors
that listen to attributes of segments and locations. These are:

CustomerEngineReactor -- watches Customer locations and when they have the appropriate attributes set
                         schedules an injection activity.
LocationEngineReactor -- watches locations and is responsible for scheduling the forwarding activity
SegmentEngineReactor -- watches segments and schedules the TransferActivity and its reactor.

There are also several other reactors used for other tasks.

ActivityReactor -- the activity manager listens to each activity. When an activity's nextTime or 
                   status changes this potentially triggers an update in the priority queue.

LocationShipmentMonitor -- locations listen to themselves. When shipments are added they track
                           various statistics.

SegmentCapacityReactor -- when a ForwardingActivityReactor can't forward a shipment onto a segment,
                          it uses a SegmentCapacityReactor to listen to the segment for shipment
                          deletion. When space frees up it sets the ForwardingActivityReactor's 
                          Activity's status to "ready" so that it is scheduled and the forwarder
                          can attempt to forward its shipment again.

Note: Once the simulation has been started (nowIs > 0) we no longer allow the deletion of segments
or locations. This is because we couldn't come up with a reasonable way to interpret the deletion
of a segment or location that has shipments on it.


Routing
-------
We preprocess the network at the start of the simulation (the first time the client sets the `now`
attribute through the activityManagerRep) to generate routing tables. We run a Connect query between
every pair A,B of nodes and record all possible routes from node A to node B. This increases simulation
startup time but speeds up building the network and running the simulation, which we thought was a
reasonable tradeoff.

Optimization
------------
Calculating every possible route from A to B allows us to pick a random route for each package, which
helps evenly distribute packages over the network to reduce congestion.

Part 4
======

We implemented the realtime activity manager by adding optional `step` and `speed` attributes
to the activity manager. `step` is the maximum number of hours forward through time the manager
is allowed to move before logging its progress (though it will stop earlier if an activity needs
to execute). `step` = 0 signifies virtual time, and `step` > 0 turns on realtime simulation.
The `speed` attribute sets the number of virtual hours that should pass per wall-clock second.

Part 5
======

Verification
-----------

For verification we constructed a very simple 4 location topology. This was intentional. Our topology
looks like:

      A
      |
      |
      B
     / \
    /   \ 
   C     D

where A is the destination, B is a truck terminal and C and D are customers.

The transfer rate of each of the customers is set to once per hour and the shipment size to 1000.
Combined with the other parameters that are set, this means that it takes 1000 hours to transmit one 
shipment over one segment.

Time is advanced to hour 10000. Depending on the capacities of the various nodes, we expect different
outputs. If A-B has capacity 1, and C-B, D-B have capacity 10, we get:

Received shipments: 10.00 (on B-A)
Refused shipments: 17443.00 (on B-A)
Delivered shipments: 9.00
Average latency: 5957.33
Total cost: 18.00

This is what we would expect. Since it takes 1000 hours per segment transfer, and there are two segments
between C/D and A, and B-A has capacity 1, we ought to have 9 shipments succeed in passing over it.

Furthermore, we expect to have a 10th shipment sitting on B-A.

The rest of the numbers are harder to predict but are reasonable. Since 9 packages travel 2 segments at 
a cost of 1 each, Total cost: 18 is correct. 

An average latency of around 6000 makes sense. since everyone has to wait at least 2000 hours, and 
then an additional 1000 hours for each position in the line. Some of the shipments are alive for
less time than others so there is some minor variation.

A very large number of refused shipments should be expected since each time a shipment is delivered,
every shipment buffered on B attempts to forward itself onto B-A.

Now we can adjust other parameters.

If we set the fleet's speed to 10 instead of 1 we get:

Received shipments: 100.00
Refused shipments: 2054047.00
Delivered shipments: 99.00
Average latency: 5075.75
Total cost: 198.00

Since we are able to move packages 10 times faster these numbers all make sense.

We should have more refused shipments since each delivery triggers everything on B to attempt to reforward.
We have lower latency because things get over the segments faster. 
We deliver more shipments since it takes 100 hours each instead of 1000.

Now let's set speed back to 1 and adjust the capacity. We will set the capacity of B-A to 2.

Received shipments: 20.00
Refused shipments: 18063.00
Delivered shipments: 18.00
Average latency: 5996.00
Total cost: 36.00

The shipment counts all make sense. By doubling the capacity we get twice as much through on the line.
More interesting is latency. Why did it increase? Well, think about the case of capacity 1. Since we have
two customers we were taking customer-1-shipment-1, customer-2-shipment-1, ... up to customer-2-shipment-5.

Now that we are doing 2 at a time, we go from customer-1-shipment-1 to customer-2-shipment-10. These later
shipments had to wait around longer so they skew the average higher.

Similarly, refused shipments doesn't increase spectacularly. This is because the same # of packages are
buffered on B. The reason it increases is because there are more deliveries. This causes more refusals
as forwarders are woken up.

Now let's set B-A capacity to 10 and C-B and D-B capacities to 1.

Received shipments: 20.00
Refused shipments: 0.00
Delivered shipments: 18.00
Average latency: 5996.00
Total cost: 36.00

Note that it's the same as before except that refused shipments is 0 now. This is because there is enough
capacity to serve everything that C and D manage to get onto B. In reality we could probably have kept
B-A's capacity at 2.

These experiments were the things that we used to verify to ourselves that our code was working.


OTHER NOTES:
=======

We decided to change BaseNotifiee so that Notifier classes maintain a list of Notifiees rather than
a single one. This proved useful in our code as we have several notifiees on single objects frequently.

We consider a "refused shipment" to be a shipment which we attempted to forward onto a segment but
instead had to wait for additional capacity.



==============================================================================================

Assignment 2 README:

There is a full unit test suite provided in unit-tests.

Our example program is UnitedStatesCities

As required by the assignment description we split our code into two parts: the rep layer and 
the engine layer. 

The rep layer expands only slightly on the heirarchy that was present in 
the starter code: we force every Rep to descend from InstanceImpl in order to give us the 
ability to add a little bit of housekeeping information in. For each class of entity
there is a corresponding Rep class. LocationRep, SegmentRep, etc. Each of these maintains
a reference to the InstanceManager that created it. The reps all access the engine through
the reference thta the InstanceManager holds.

The Engine layer is more complicated. We have two "classes" of class in our engine layer.
There are "Entitys" which are as described in the class. Entity objects inherit from 
PtrInterface and are required to have a name. There are also "Ordinal" types which 
inherit from the given Ordinal class. These types are unnamed and are never used with
pointers. Each ordinal type implements a "string" operator that is appropriate to its type
and also has a constructor which limits them to valid values.

There are several kinds of entities. In our system we have:

* fleet
* location
** terminal
*** boat terminal
*** plane terminal
*** truck terminal
** customer
** port
* segment
* statistics
* connectivity

Each of these types of entities has its own class. 

Over all of these entities there is an Engine object. The engine is responsible for holding
references (indexed by name) to each of the entities in the simulation. It also holds all 
of the factory methods for creating entities and provides a Notifiee interface that allows
Statistics objects to listen to it.


Design decisions:
==========

We decided to store non-existent return segments and sources as "NULL" values in the corresponding
attributes. This leads to a few issues with null checking, and also makes it slightly
difficult to distinguish between an invalid name and an uninitialized property at the engine layer.
We deal with this by checking at the rep layer that all names that are used to assign "source"
and "return segment" are valid.

We also implemented the bookkeeping associated with returnSegments and deleting sources without
notifications. We felt that it was simpler for our use case.

Error handling:

We decided to handle errors by throwing exceptions at the engine layer. These exceptions bubble 
to the rep layer where they are caught by catch statements in #attribute and #attributeIs in 
the appropriate rep classes. At this point an error message is logged. The exception types
are generic but include specific messages as members. We did not choose to display 
the more detailed error messages although this is certainly a possibility.


Semantics:
========

We have implemented our collections according to Cheriton's semantics. In general they return "NULL"
for missing elements, and they never throw exceptions.

Our mutators are all exception-free (except for when invalid values are set.)
Our getters are all nilpotent.

Our notifications all implement synchronous processing as opposed to asynchronous processing.
There are a few instances where this assumption matters (mostly for statistics) but this would
be fixable.
